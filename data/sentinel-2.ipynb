{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Sentinel-2 data on Azure\n",
    "\n",
    "The [Sentinel-2](https://sentinel.esa.int/web/sentinel/missions/sentinel-2) program provides global imagery in thirteen spectral bands at 10m-60m resolution and a revisit time of approximately five days.  This dataset represents the global Sentinel-2 archive, from 2016 to the present, processed to L2A (bottom-of-atmosphere) using [Sen2Cor](https://step.esa.int/main/snap-supported-plugins/sen2cor/) and converted to [cloud-optimized GeoTIFF](https://www.cogeo.org/) format.\n",
    "\n",
    "This notebook demonstrates access to Sentinel-2 data on Azure, using sentinelsat to query the Copernicus Open Access Hub for scenes, then accessing the scenes on Azure blob storage.  Using this approach, the user needs to provide storage credentials.  To access the Copernicus Open Access Hub for spatiotemporal search, the user also needs to provide Open Access Hub credentials.  An alternative approach that eliminates both of these requirements is to use the Planetary Computer API, demonstrated [here](https://planetarycomputer.microsoft.com/dataset/sentinel-2-l2a#Example-Notebook).\n",
    "\n",
    "This dataset is stored in the West Europe Azure region, so this notebook will run most efficiently on Azure compute located in the same region.  If you are using this data for environmental science applications, consider applying for an [AI for Earth grant](http://aka.ms/ai4egrants) to support your compute requirements.\n",
    "\n",
    "This dataset is documented at [aka.ms/ai4edata-sentinel-2](http://aka.ms/ai4edata-sentinel-2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "from pyproj import Transformer        \n",
    "\n",
    "from sentinelsat import SentinelAPI\n",
    "from azure.storage.blob import ContainerClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This can be either a SAS token or a file with a SAS token on the first line\n",
    "sentinel2_sas_token = os.path.expanduser('~/tokens/sentinel2_ro_sas.txt')\n",
    "\n",
    "# A text file with a login on the first line, password on the second line\n",
    "copernicus_credentials_file = os.path.expanduser('~/tokens/coah_username_password.txt')\n",
    "\n",
    "# Or specify username/password\n",
    "username = None; password = None\n",
    "\n",
    "# Copernicus API query parameters\n",
    "api_url = 'https://scihub.copernicus.eu/dhus'\n",
    "platform_name = 'Sentinel-2'\n",
    "\n",
    "# Query just L1C scenes; L2A scenes have the same timestamps/geometries\n",
    "product_type = 'S2MSI1C'\n",
    "\n",
    "# Query parameters\n",
    "\n",
    "# Around Jonah Bay, Alaska\n",
    "lat = 61.00212860030653\n",
    "lon = -147.7789234838648\n",
    "\n",
    "# Format point as WKT\n",
    "footprint = 'POINT({:.4f} {:.4f})'.format(lon,lat)\n",
    "start_time = datetime.datetime(2019,6,1,0,0,0)\n",
    "end_time = datetime.datetime(2019,8,1,0,0,0)\n",
    "max_cloud_cover_percent = 5\n",
    "\n",
    "# Scaling constant that controls rendering brightness\n",
    "preview_norm_value = 1500\n",
    "\n",
    "# When rendering whole images, how much should we downscale?\n",
    "preview_downsample_factor = 20\n",
    "\n",
    "# Select channels for our composite\n",
    "channels = ['_B04','_B03','_B02']\n",
    "\n",
    "# Target image size and \"zoom factor\"\n",
    "target_size = [720,405]\n",
    "oversample = 12.5\n",
    "\n",
    "# Scaling constant that controls rendering brightness\n",
    "composite_norm_value = 3000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create sentinel-2 container client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(sentinel2_sas_token):\n",
    "    lines = []\n",
    "    with open(sentinel2_sas_token,'r') as f:\n",
    "        lines = f.readlines()\n",
    "    assert len(lines) >= 1\n",
    "    sentinel2_sas_token = lines[0].strip()\n",
    "\n",
    "sentinel2_storage_account_name = 'sentinel2l2a01'\n",
    "sentinel2_container_name = 'sentinel2-l2'\n",
    "\n",
    "sentinel2_storage_account_url = 'https://' + sentinel2_storage_account_name + '.blob.core.windows.net/'\n",
    "\n",
    "sentinel2_container_client = ContainerClient(account_url=sentinel2_storage_account_url, \n",
    "                                             container_name=sentinel2_container_name,\n",
    "                                             credential=sentinel2_sas_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load username/pw for Open Access Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if copernicus_credentials_file is not None:\n",
    "\n",
    "    assert username is None \n",
    "    assert password is None    \n",
    "\n",
    "    lines = []\n",
    "    with open(copernicus_credentials_file,'r') as f:\n",
    "        lines = f.readlines()\n",
    "    assert len(lines) >= 2\n",
    "    \n",
    "    username = lines[0].strip()\n",
    "    password = lines[1].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the Open Access Hub API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = SentinelAPI(user=username, password=password, api_url=api_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query for scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = api.query(footprint,\n",
    "                     producttype=product_type,\n",
    "                     date=(start_time,end_time),\n",
    "                     platformname=platform_name,\n",
    "                     cloudcoverpercentage=(0, max_cloud_cover_percent))\n",
    "\n",
    "product_values = list(products.values())\n",
    "    \n",
    "print('Found {} scenes:'.format(len(products)))\n",
    "for p in product_values:\n",
    "    print(p['filename'])\n",
    "\n",
    "# For the rest of this notebook, we'll use the first returned result\n",
    "product = product_values[0]   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map to Azure paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the product:\n",
    "#\n",
    "# S2B_MSIL1C_20190730T190919_N0208_R056_T10UEU_20190730T210627.SAFE\n",
    "#    \n",
    "# Our path is:\n",
    "#    \n",
    "# https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2\n",
    "#\n",
    "# /10/U/EU/2019/07/30/S2B_MSIL2A_20190730T190919_N0212_R056_T10UEU_20201005T200819.SAFE/\n",
    "#\n",
    "# This part is unique and can be determined from the scene metadata:\n",
    "#\n",
    "# /10/U/EU/2019/07/30/S2B_MSIL2A_20190730T190919\n",
    "\n",
    "# E.g. '10UEU'\n",
    "tile_id = product['tileid']\n",
    "\n",
    "utm_lon_zone = tile_id[0:2]\n",
    "mgrs_lat_band = tile_id[2]\n",
    "tile_chunk = tile_id[3:5]\n",
    "\n",
    "scene_date = product['datatakesensingstart']\n",
    "scene_year = str(scene_date.year)\n",
    "scene_month = str(scene_date.month).zfill(2)\n",
    "scene_day = str(scene_date.day).zfill(2)\n",
    "\n",
    "filename = product['filename'].replace('L1C','L2A')\n",
    "filename = filename[0:26]\n",
    "\n",
    "azure_scene_prefix = '/'.join([utm_lon_zone,mgrs_lat_band,tile_chunk,scene_year,scene_month,scene_day,filename])\n",
    "\n",
    "print('Azure scene prefix: {}'.format(azure_scene_prefix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List matching blobs, select the three channels we want for RGB rendering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = sentinel2_container_client.list_blobs(name_starts_with=azure_scene_prefix)\n",
    "image_blobs = [blob.name for blob in generator if blob.name.endswith('.tif')]\n",
    "preview_blobs = [blob.name for blob in generator if blob.name.endswith('.jpeg')]\n",
    "\n",
    "print('Found {} image files'.format(len(image_blobs)))\n",
    "\n",
    "# Find three channels in our preferred RGB ordering\n",
    "channels = ['_B04','_B03','_B02']\n",
    "\n",
    "rgb_blobs = []\n",
    "for c in channels:\n",
    "    for blob_path in image_blobs:\n",
    "        if c in blob_path:\n",
    "            rgb_blobs.append(blob_path)\n",
    "            break\n",
    "\n",
    "print('\\nRendering an RGB composite from the following image files:\\n')\n",
    "assert(len(rgb_blobs) == 3)\n",
    "for blob_path in rgb_blobs:\n",
    "    print(blob_path.split('/')[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to Azure blob URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_urls = []\n",
    "for blob_path in rgb_blobs:\n",
    "    rgb_urls.append(sentinel2_storage_account_url + sentinel2_container_name + '/' + blob_path + sentinel2_sas_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Render a composite image for the whole scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = None; h = None;\n",
    "image_data = []\n",
    "\n",
    "for url in rgb_urls:\n",
    "    with rasterio.open(url,'r') as raster:        \n",
    "        h = int(raster.height // preview_downsample_factor)\n",
    "        w = int(raster.width // preview_downsample_factor)\n",
    "        \n",
    "        band_array = raster.read(1, out_shape=(1,h,w))\n",
    "        raster.close()\n",
    "        band_array = band_array / composite_norm_value\n",
    "        image_data.append(band_array)\n",
    "\n",
    "rgb = np.dstack((image_data[0],image_data[1],image_data[2]))\n",
    "np.clip(rgb,0,1,rgb)\n",
    "\n",
    "dpi = 100; fig = plt.figure(frameon=False,figsize=(w/dpi,h/dpi),dpi=dpi)\n",
    "ax = plt.Axes(fig,[0., 0., 1., 1.]); ax.set_axis_off(); fig.add_axes(ax)\n",
    "\n",
    "plt.imshow(rgb);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop to our target size around our target point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = []\n",
    "\n",
    "for urls in rgb_urls:\n",
    "    \n",
    "    with rasterio.open(urls,'r') as src:\n",
    "        \n",
    "        xsize = (target_size[0] * oversample)\n",
    "        ysize = (target_size[1] * oversample)\n",
    "                \n",
    "        transformer = Transformer.from_crs('EPSG:4326', src.crs, always_xy=True)\n",
    "        xx, yy = transformer.transform(lon, lat)\n",
    "        py, px = src.index(xx,yy)    \n",
    "        xoff = px - xsize // 2 \n",
    "        yoff = py - ysize // 2 \n",
    "        window = Window(xoff,yoff,xsize,ysize)\n",
    "        \n",
    "        band_array = src.read(1, window=window)\n",
    "        src.close()\n",
    "        band_array = band_array / composite_norm_value\n",
    "        image_data.append(band_array)\n",
    "\n",
    "    # ...with rasterio.open()\n",
    "    \n",
    "# ...for each file\n",
    "\n",
    "rgb = np.dstack((image_data[0],image_data[1],image_data[2]))\n",
    "np.clip(rgb,0,1,rgb)\n",
    "\n",
    "w = target_size[0]; h = target_size[1]\n",
    "dpi = 100; fig = plt.figure(frameon=False,figsize=(w/dpi,h/dpi),dpi=dpi)\n",
    "ax = plt.Axes(fig,[0., 0., 1., 1.]); ax.set_axis_off(); fig.add_axes(ax)\n",
    "\n",
    "plt.imshow(rgb);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
