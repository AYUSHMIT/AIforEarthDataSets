{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Sentinel-3 data on Azure\n",
    "\n",
    "The [Sentinel-3](https://sentinel.esa.int/web/sentinel/missions/sentinel-3) mission provides global multispectral imagery at a resolution of 300m-500m, with a revisit time of approximately two days, from 2016 to the present, in NetCDF format.\n",
    "\n",
    "This notebook demonstrates access to Sentinel-3 data on Azure, using sentinelsat to query the Copernicus Open Access Hub for scenes, then accessing the scenes on Azure blob storage.  Because Sentinel-3 data are in preview on Azure, the user needs to provide storage credentials.  To access the Copernicus Open Access Hub for spatiotemporal search, the user also needs to provide Open Access Hub credentials.  This data will soon be available via the [Planetary Computer API](https://planetarycomputer.microsoft.com), which will eliminate the need for manually providing credentials.\n",
    "\n",
    "This dataset is stored in the West Europe Azure region, so this notebook will run most efficiently on Azure compute located in the same region.  If you are using this data for environmental science applications, consider applying for an [AI for Earth grant](http://aka.ms/ai4egrants) to support your compute requirements.\n",
    "\n",
    "This dataset is documented at [aka.ms/ai4edata-sentinel-3](http://aka.ms/ai4edata-sentinel-3).\n",
    "\n",
    "Sentinel-3 data on Azure are maintained by [Sinergise](https://sinergise.com/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fsspec\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from azure.storage.blob import ContainerClient\n",
    "\n",
    "# Not used directly, but needs to be installed to read NetCDF files with xarray\n",
    "import h5netcdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auth files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A plain-text file with a SAS token (starting with \"?sv\") on the first line\n",
    "sas_file = os.path.expanduser('~/tokens/sentinel-5p_sas.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at ozone concentration from mid-day on Jan 1, 2021\n",
    "product = 'L2__O3____'\n",
    "date = '2021/01/01'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Azure storage constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "with open(sas_file,'r') as f:\n",
    "    lines = f.readlines()\n",
    "assert len(lines) >= 1\n",
    "sas_token = lines[0].strip()\n",
    "        \n",
    "storage_account_name = 'sentinel5euwest'\n",
    "container_name = 'sentinel-5p'\n",
    "storage_account_url = 'https://' + storage_account_name + '.blob.core.windows.net/'\n",
    "\n",
    "container_client = ContainerClient(account_url=storage_account_url, \n",
    "                                                 container_name=container_name,\n",
    "                                                 credential=sas_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List products matching our product/date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = '/'.join(['TROPOMI',product,date])\n",
    "print('Searching for prefix {}'.format(prefix))\n",
    "generator = container_client.list_blobs(name_starts_with=prefix)\n",
    "scene_paths = [blob.name for blob in generator]\n",
    "print('\\nFound {} matching scenes:\\n'.format(len(scene_paths)))\n",
    "for s in scene_paths:\n",
    "    print(s.split('/')[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print metadata for one scene\n",
    "\n",
    "Choose an OFFL scene for this product/date (NRTI products have smaller domains).  In practice the scene we choose impacts\n",
    "the longitude we're plotting, since S5P has a daily orbit.  We'll choose a mid-day scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offl_scenes = [s for s in scene_paths if 'OFFL' in s]\n",
    "scene_path = offl_scenes[len(offl_scenes) // 2]\n",
    "url = storage_account_url + container_name + '/' + scene_path\n",
    "print('Processing image at URL:\\n{}'.format(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings; warnings.filterwarnings('ignore')\n",
    "with fsspec.open(url+sas_token) as f:\n",
    "    ds = xr.open_dataset(f)\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open the data\n",
    "\n",
    "...which lives in the 'PRODUCT' NetCDF group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with fsspec.open(url+sas_token) as f:\n",
    "    ds = xr.open_dataset(f,group='/PRODUCT')\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the data in its native coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'CH4' in product:\n",
    "    varname = 'methane_mixing_ratio'\n",
    "elif 'NO2' in product:\n",
    "    varname = 'nitrogendioxide_tropospheric_column'\n",
    "elif 'O3' in product:\n",
    "    varname = 'ozone_total_vertical_column'\n",
    "elif 'CO' in product:\n",
    "    varname = 'carbonmonoxide_total_column'\n",
    "elif 'SO2' in product:\n",
    "    varname = 'sulfurdioxide_total_vertical_column'\n",
    "    \n",
    "data = ds[varname][0,:,:]\n",
    "data.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract values as numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = data.values\n",
    "lon = ds['longitude'].values.squeeze()\n",
    "lat = ds['latitude'].values.squeeze()\n",
    "\n",
    "# Don't plot extreme latitudes; they make it hard to zoom in a nice way\n",
    "minlat = -60; maxlat = 60\n",
    "\n",
    "# Zoom to a sensible longitude area by plotting only values that are non-nan\n",
    "# and above a threshold.\n",
    "plot_threshold = np.nanpercentile(z,50)\n",
    "\n",
    "valid_indices = np.argwhere((~np.isnan(z)) & (z > plot_threshold))\n",
    "\n",
    "minlon = None; maxlon = None\n",
    "for xy in valid_indices:\n",
    "    xy_lon = lon[xy[0],xy[1]]\n",
    "    xy_lat = lat[xy[0],xy[1]]\n",
    "    if xy_lat > maxlat or xy_lat < minlat:\n",
    "        continue\n",
    "    if minlon is None or xy_lon < minlon:\n",
    "        minlon = xy_lon\n",
    "    if maxlon is None or xy_lon > maxlon:\n",
    "        maxlon = xy_lon\n",
    "\n",
    "plot_extent = (minlon, maxlon, minlat, maxlat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot on a basemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "from cartopy.feature import NaturalEarthFeature\n",
    "\n",
    "figure, ax = plt.subplots(figsize=(15, 10))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree(central_longitude=0.0))\n",
    "\n",
    "# Prepare the background and axes\n",
    "boundaries = cfeature.NaturalEarthFeature(\n",
    "    category='cultural',name='admin_0_countries',scale='50m',facecolor='none')\n",
    "ax.add_feature(boundaries, edgecolor='lightgray')\n",
    "gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True,\n",
    "                  linewidth=1, color='gray', alpha=0.5, linestyle=':')\n",
    "gl.xformatter = LONGITUDE_FORMATTER; gl.yformatter = LATITUDE_FORMATTER\n",
    "ax.set_extent(plot_extent,ccrs.PlateCarree())\n",
    "\n",
    "# Plot\n",
    "plt.contourf(lon, lat, z, 50, transform=ccrs.PlateCarree())\n",
    "plt.colorbar(fraction=0.015, pad=0.08)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
