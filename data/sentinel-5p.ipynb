{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Sentinel-5P data on Azure\n",
    "\n",
    "The [Sentinel-5P](https://sentinel.esa.int/web/sentinel/missions/sentinel-5p) mission provides daily global atmospheric measurements at a resolution of 3.5km x 7km on most bands.  This dataset represents the global archive of Sentinel-5P [Level 2](http://www.tropomi.eu/data-products/level-2-products) products, from 2018 to the present, in NetCDF format.  \n",
    "\n",
    "This notebook demonstrates basic access to Sentinel-5 data on Azure.  Because Sentinel-1 data are in preview, the user needs to provide storage credentials.\n",
    "\n",
    "This dataset is stored in the West Europe Azure region, so this notebook will run most efficiently on Azure compute located in the same region.  If you are using this data for environmental science applications, consider applying for an [AI for Earth grant](http://aka.ms/ai4egrants) to support your compute requirements.\n",
    "\n",
    "This dataset is documented at [aka.ms/ai4edata-sentinel-5p](http://aka.ms/ai4edata-sentinel-5p).\n",
    "\n",
    "Sentinel-5P data on Azure are maintained by [Sinergise](https://sinergise.com/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fsspec\n",
    "import xarray as xr\n",
    "from azure.storage.blob import ContainerClient\n",
    "\n",
    "# Not used directly, but needs to be installed to read NetCDF files with xarray\n",
    "import h5netcdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auth files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A plain-text file with a SAS token (starting with \"?sv\") on the first line\n",
    "sas_file = os.path.expanduser('~/tokens/sentinel-5p_sas.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product = 'L2__CH4___'\n",
    "date = '2020/01/01'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Azure storage constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "with open(sas_file,'r') as f:\n",
    "    lines = f.readlines()\n",
    "assert len(lines) >= 1\n",
    "sas_token = lines[0].strip()\n",
    "        \n",
    "storage_account_name = 'sentinel5euwest'\n",
    "container_name = 'sentinel-5p'\n",
    "storage_account_url = 'https://' + storage_account_name + '.blob.core.windows.net/'\n",
    "\n",
    "container_client = ContainerClient(account_url=storage_account_url, \n",
    "                                                 container_name=container_name,\n",
    "                                                 credential=sas_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List products matching our product/date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = '/'.join(['TROPOMI',product,date])\n",
    "print(prefix)\n",
    "generator = container_client.list_blobs(name_starts_with=prefix)\n",
    "scene_paths = [blob.name for blob in generator]\n",
    "print('Found {} matching scenes:\\n'.format(len(scene_paths)))\n",
    "for s in scene_paths:\n",
    "    print(s.split('/')[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print metadata for one scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the first scene for this product/date\n",
    "scene_path = scene_paths[0]\n",
    "url = storage_account_url + container_name + '/' + scene_path\n",
    "print('Processing image at URL:\\n{}'.format(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings; warnings.filterwarnings('ignore')\n",
    "with fsspec.open(url+sas_token) as f:\n",
    "    ds = xr.open_dataset(f)\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with fsspec.open(url+sas_token) as f:\n",
    "    ds = xr.open_dataset(f,group='PRODUCT')\n",
    "print(ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
